package com.bakdata.conquery.models.preproc;

import java.util.Arrays;
import java.util.Map;
import java.util.StringJoiner;
import java.util.stream.Collectors;

import com.bakdata.conquery.models.datasets.Column;
import com.bakdata.conquery.models.datasets.Import;
import com.bakdata.conquery.models.datasets.ImportColumn;
import com.bakdata.conquery.models.datasets.Table;
import com.bakdata.conquery.models.events.MajorTypeId;
import com.bakdata.conquery.models.events.stores.root.ColumnStore;
import com.fasterxml.jackson.annotation.JsonCreator;
import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.Getter;
import lombok.NoArgsConstructor;
import lombok.Setter;
import lombok.extern.slf4j.Slf4j;

/**
 * Header containing data about a Preprocessed Csv file. Generated by running {@link com.bakdata.conquery.commands.PreprocessorCommand}.
 *
 * @implSpec The Columns and their order must directly match the layout in the data.
 */
@Data
@Getter @Setter
@NoArgsConstructor(onConstructor_ = {@JsonCreator})
@AllArgsConstructor
@Slf4j
public class PreprocessedHeader {
	/**
	 * The name/tag of an import.
	 */
	private String name;

	/**
	 * The specific table id to be loaded into.
	 */
	private String table;

	/**
	 * Number of rows in the Preprocessed file.
	 */
	private long rows;
	private long numberOfEntities;

	private int numberOfBuckets;

	/**
	 * The specific columns and their associated MajorType for validation.
	 */
	private PPColumn[] columns;

	/**
	 * A hash to check if any of the underlying files for generating this CQPP has changed.
	 */
	private int validityHash;

	public Import createImportDescription(Table table, Map<String, ColumnStore> stores) {
		final Import imp = new Import(table);

		imp.setName(getName());
		imp.setNumberOfEntries(getRows());
		imp.setNumberOfEntities(getNumberOfEntities());

		final ImportColumn[] importColumns = new ImportColumn[columns.length];

		for (int i = 0; i < columns.length; i++) {
			final ColumnStore store = stores.get(columns[i].getName());

			final ImportColumn col = new ImportColumn(imp, store.createDescription(), store.getLines(), numberOfBuckets * store.estimateMemoryConsumptionBytes());

			col.setName(columns[i].getName());

			importColumns[i] = col;
		}

		imp.setColumns(importColumns);

		return imp;
	}


	/**
	 * Verify that the supplied table matches the preprocessed' data in shape.
	 */
	public void assertMatch(Table table) {
		final StringJoiner errors = new StringJoiner("\n");

		if (table.getColumns().length != getColumns().length) {
			errors.add(String.format("Import column count=`%d` does not match table column count=`%d`", getColumns().length, table.getColumns().length));
		}

		final Map<String, MajorTypeId> typesByName = Arrays.stream(getColumns())
													   .collect(Collectors.toMap(PPColumn::getName, PPColumn::getType));

		for (int i = 0; i < Math.min(table.getColumns().length, getColumns().length); i++) {
			final Column column = table.getColumns()[i];

			if(!typesByName.containsKey(column.getName())){
				errors.add(String.format("Column[%s] is missing.", column.getName()));
			}
			else if (!typesByName.get(column.getName()).equals(column.getType())) {
				errors.add(String.format("Column[%s] Types do not match %s != %s"
						, column.getName(),  typesByName.get(column.getName()), column.getType())
				);
			}
		}

		if (errors.length() != 0) {
			log.error("Problems concerning Import `{}`:\n{}", name, errors);
			throw new IllegalArgumentException(String.format("Headers[%s.%s] do not match Table[%s]. More info in logs.", getTable(), getName(), table.getId()));
		}
	}


}
